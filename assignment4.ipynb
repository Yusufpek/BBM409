{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBM 409: Machine Learning Laboratory - Assignment 4\n",
    "### Spring 2025\n",
    "**Instructor:** Prof. Dr. Ahmet Burak Can\n",
    "**TA:** R.A. Görkem Akyıldız\n",
    "\n",
    "**Group ID:** `<Your Group ID>`\n",
    "**Group Members:** `<Your Names>`\n",
    "\n",
    "**Due Date:** 01.06.2025 (23:00)\n",
    "**Programming Language:** Python 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Classification is a fundamental task in machine learning and human cognition. Historically, the ability to classify objects, for instance, as threats or non-threats, was crucial for survival. Modern classification tasks have become more complex and detailed, such as identifying species of animals or plants. As tasks become more detailed, their difficulty increases. To manage these complexities efficiently, we leverage computing machines. Image classification is a significant subfield of this domain. This project focuses on classifying bird species using neural networks and other machine learning techniques.\n",
    "\n",
    "The aim of this project is to explore various machine learning approaches for classifying bird species from a given dataset. We will start with traditional feature extraction methods coupled with classical machine learning algorithms. Then, we will investigate dimensionality reduction techniques like PCA and other feature selection methods. Subsequently, we will delve into deep learning by fine-tuning pre-trained Convolutional Neural Network (CNN) models and training CNN models from scratch (both with random weights and custom architectures). A key aspect of this project will be extensive experimentation, robust evaluation using multiple metrics (Accuracy, Precision, Recall, F1-Score), and detailed interpretation of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Setup\n",
    "\n",
    "The dataset for this project contains twenty-five species of birds in India, with 1,500 samples for each species. The original samples are separated as 1,200 for training and 300 for validation per species. In total, there are 37,500 images, each approximately 1 MP.\n",
    "\n",
    "For this assignment, we need to achieve an 80% training, 10% testing, and 10% validation split. We will do this by:\n",
    "* Using all 1,200 images per species from the original `train` directory as our **training set (80%)**.\n",
    "* Splitting the 300 images per species from the original `valid` directory randomly in half:\n",
    "    * 150 images per species for our **new validation set (10%)**.\n",
    "    * The remaining 150 images per species for our **test set (10%)**.\n",
    "\n",
    "We will **not** be physically copying these files. Instead, we will generate lists of file paths for each set and use these lists to load data on-the-fly. This approach aligns with the project's allowance to \"work with a subset of the dataset\" or use it as desired if computational power is a concern, by avoiding unnecessary duplication.\n",
    "\n",
    "**Dataset Source:** [Kaggle Indian Birds Species Image Classification Dataset](https://www.kaggle.com/datasets/ichhadhari/indian-birds/data)\n",
    "\n",
    "**Important Considerations from the Assignment:**\n",
    "* You are free to downscale images if computational resources are a constraint.\n",
    "* The primary focus is on your interpretations and implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import cv2 # OpenCV for image processing\n",
    "from PIL import Image # Pillow for image processing\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Deep Learning Libraries (TensorFlow/Keras)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0 \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"NumPy Version:\", np.__version__)\n",
    "print(\"OpenCV Version:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset Path Configuration ---\n",
    "# !!! IMPORTANT: Update this path to where you've downloaded and extracted the dataset !!!\n",
    "# This should point to the directory that contains 'train' and 'valid' subfolders (e.g., \"Birds_25\")\n",
    "BASE_DATA_DIR = \"Birds_25\" # Example: \"./Birds_25\" if it's in the current directory\n",
    "\n",
    "# Check if the dataset path exists\n",
    "original_train_data_path = os.path.join(BASE_DATA_DIR, \"train\")\n",
    "original_valid_data_path = os.path.join(BASE_DATA_DIR, \"valid\")\n",
    "\n",
    "if not os.path.exists(BASE_DATA_DIR):\n",
    "    print(f\"ERROR: Base dataset directory not found at {BASE_DATA_DIR}\")\n",
    "    print(\"Please download the dataset from https://www.kaggle.com/datasets/ichhadhari/indian-birds/data\")\n",
    "    print(\"and update the BASE_DATA_DIR variable in this cell to point to the folder containing 'train' and 'valid' (e.g., 'Birds_25').\")\n",
    "elif not os.path.exists(original_train_data_path) or not os.path.isdir(original_train_data_path):\n",
    "    print(f\"ERROR: Original 'train' directory not found in {BASE_DATA_DIR}\")\n",
    "    print(\"Please ensure BASE_DATA_DIR is set correctly.\")\n",
    "elif not os.path.exists(original_valid_data_path) or not os.path.isdir(original_valid_data_path):\n",
    "    print(f\"ERROR: Original 'valid' directory not found in {BASE_DATA_DIR}\")\n",
    "    print(\"Please ensure BASE_DATA_DIR is set correctly.\")\n",
    "else:\n",
    "    print(f\"Dataset base directory found at: {os.path.abspath(BASE_DATA_DIR)}\")\n",
    "    print(f\"Original training data path: {os.path.abspath(original_train_data_path)}\")\n",
    "    print(f\"Original validation data path: {os.path.abspath(original_valid_data_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to Prepare File Lists and Labels (80-10-10 split) ---\n",
    "def prepare_dataset_file_lists(base_dir):\n",
    "    \"\"\"\n",
    "    Prepares lists of image file paths and labels for train, validation, and test sets\n",
    "    without copying files. Achieves an 80-10-10 split as per assignment.\n",
    "    \"\"\"\n",
    "    train_image_paths = []\n",
    "    train_labels_str = []\n",
    "    val_image_paths = []\n",
    "    val_labels_str = []\n",
    "    test_image_paths = []\n",
    "    test_labels_str = []\n",
    "\n",
    "    original_train_path = os.path.join(base_dir, \"train\")\n",
    "    original_valid_path = os.path.join(base_dir, \"valid\")\n",
    "\n",
    "    if not os.path.isdir(original_train_path) or not os.path.isdir(original_valid_path):\n",
    "        print(\"Error: 'train' or 'valid' subdirectories not found in base_dir.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    species_list = sorted([d for d in os.listdir(original_train_path) if os.path.isdir(os.path.join(original_train_path, d))])\n",
    "    if not species_list:\n",
    "        print(\"No species found in the training directory.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    print(f\"Found {len(species_list)} species: {species_list[:5]}...\")\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(species_list) # Fit on all species names\n",
    "    class_names = list(label_encoder.classes_)\n",
    "\n",
    "    for species_name in species_list:\n",
    "        # 1. Training set (80%)\n",
    "        species_train_dir = os.path.join(original_train_path, species_name)\n",
    "        if os.path.isdir(species_train_dir):\n",
    "            for img_name in os.listdir(species_train_dir):\n",
    "                img_path = os.path.join(species_train_dir, img_name)\n",
    "                if os.path.isfile(img_path):\n",
    "                    train_image_paths.append(os.path.abspath(img_path))\n",
    "                    train_labels_str.append(species_name)\n",
    "        \n",
    "        # 2. Validation and Test sets (from original 'valid' directory)\n",
    "        species_original_valid_dir = os.path.join(original_valid_path, species_name)\n",
    "        if os.path.isdir(species_original_valid_dir):\n",
    "            current_species_original_valid_files = []\n",
    "            for img_name in os.listdir(species_original_valid_dir):\n",
    "                img_path = os.path.join(species_original_valid_dir, img_name)\n",
    "                if os.path.isfile(img_path):\n",
    "                     current_species_original_valid_files.append(os.path.abspath(img_path))\n",
    "            \n",
    "            random.shuffle(current_species_original_valid_files)\n",
    "            \n",
    "            num_original_valid = len(current_species_original_valid_files)\n",
    "            # As per assignment: split each validation set (originally 300) into half (150 val, 150 test)\n",
    "            split_point = 150 \n",
    "            if num_original_valid < 300 and num_original_valid > 0:\n",
    "                print(f\"Warning: Species {species_name} has {num_original_valid} images in original validation set (expected 300). Adjusting val/test split point to {num_original_valid // 2}.\")\n",
    "                split_point = num_original_valid // 2\n",
    "            elif num_original_valid == 0:\n",
    "                 print(f\"Warning: Species {species_name} has 0 images in original validation set.\")\n",
    "                 continue # No files to split\n",
    "\n",
    "            val_set_for_species = current_species_original_valid_files[:split_point]\n",
    "            test_set_for_species = current_species_original_valid_files[split_point : split_point * 2] # Handles cases with <300 by taking up to split_point more\n",
    "            \n",
    "            if len(val_set_for_species) == 0 and len(test_set_for_species) == 0 and num_original_valid > 0:\n",
    "                # Fallback if split_point became 0 due to very few images\n",
    "                if num_original_valid == 1:\n",
    "                    val_set_for_species = current_species_original_valid_files\n",
    "                # else leave test empty if only 1 file\n",
    "            \n",
    "            val_image_paths.extend(val_set_for_species)\n",
    "            val_labels_str.extend([species_name] * len(val_set_for_species))\n",
    "            \n",
    "            test_image_paths.extend(test_set_for_species)\n",
    "            test_labels_str.extend([species_name] * len(test_set_for_species))\n",
    "\n",
    "    # Create DataFrames for easier use with Keras flow_from_dataframe and general handling\n",
    "    train_df = pd.DataFrame({'filepath': train_image_paths, 'label': train_labels_str})\n",
    "    val_df = pd.DataFrame({'filepath': val_image_paths, 'label': val_labels_str})\n",
    "    test_df = pd.DataFrame({'filepath': test_image_paths, 'label': test_labels_str})\n",
    "    \n",
    "    # Add numeric labels\n",
    "    train_df['id'] = label_encoder.transform(train_df['label'])\n",
    "    val_df['id'] = label_encoder.transform(val_df['label'])\n",
    "    test_df['id'] = label_encoder.transform(test_df['label'])\n",
    "\n",
    "    return train_df, val_df, test_df, label_encoder, class_names\n",
    "\n",
    "# Prepare the dataset file lists\n",
    "train_df, val_df, test_df, label_encoder, class_names = prepare_dataset_file_lists(BASE_DATA_DIR)\n",
    "\n",
    "if train_df is not None:\n",
    "    print(f\"\\nDataset prepared:\")\n",
    "    print(f\"  Training samples: {len(train_df)} (Expected ~{len(class_names)*1200 if class_names else 'N/A'})\")\n",
    "    print(f\"  Validation samples: {len(val_df)} (Expected ~{len(class_names)*150 if class_names else 'N/A'})\")\n",
    "    print(f\"  Test samples: {len(test_df)} (Expected ~{len(class_names)*150 if class_names else 'N/A'})\")\n",
    "    print(f\"  Number of classes: {len(class_names) if class_names else 'N/A'}\")\n",
    "    if class_names: print(f\"  Example class names: {class_names[:5]}\")\n",
    "\n",
    "    # Save the label encoder classes for later use, especially if notebook is restarted\n",
    "    np.save('label_encoder_classes.npy', label_encoder.classes_) \n",
    "else:\n",
    "    print(\"Dataset preparation failed. Please check BASE_DATA_DIR and dataset structure.\")\n",
    "\n",
    "# Display first few rows of the dataframes\n",
    "if train_df is not None and not train_df.empty:\n",
    "    print(\"\\nTraining DataFrame head:\")\n",
    "    print(train_df.head())\n",
    "if val_df is not None and not val_df.empty:\n",
    "    print(\"\\nValidation DataFrame head:\")\n",
    "    print(val_df.head())\n",
    "if test_df is not None and not test_df.empty:\n",
    "    print(\"\\nTest DataFrame head:\")\n",
    "    print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Image Preprocessing Utilities and Data Subsetting (Optional)\n",
    "We define a target image size. Images will be loaded and resized on-the-fly.\n",
    "The assignment allows downscaling images if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 224 \n",
    "IMG_HEIGHT = 224\n",
    "IMG_CHANNELS = 3 # For color images\n",
    "TARGET_IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH) # Pillow uses (width, height), OpenCV (height, width)\n",
    "\n",
    "def preprocess_image_pil(image_path, target_size=TARGET_IMG_SIZE, normalize=True):\n",
    "    \"\"\"Loads and preprocesses a single image from its path using PIL.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB') # Ensure 3 channels\n",
    "        img = img.resize((target_size[1], target_size[0])) # PIL resize is (width, height)\n",
    "        img_array = np.array(img)\n",
    "        if normalize: # Normalization to [0,1] is typical for neural networks\n",
    "            img_array = img_array / 255.0\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        # print(f\"Error processing image {image_path} with PIL: {e}\") # Can be too verbose\n",
    "        return None\n",
    "\n",
    "def preprocess_image_cv2(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH), normalize_for_nn=False, for_feature_extraction=False):\n",
    "    \"\"\"Loads and preprocesses a single image from its path using OpenCV.\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            # print(f\"Error: OpenCV could not read image {image_path}\")\n",
    "            return None\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # OpenCV loads as BGR\n",
    "        img = cv2.resize(img, (target_size[1], target_size[0])) # cv2 resize is (width, height)\n",
    "        \n",
    "        if normalize_for_nn: # Normalization to [0,1] for neural networks\n",
    "            img_array = img.astype(np.float32) / 255.0\n",
    "            return img_array\n",
    "        elif for_feature_extraction: # Return as uint8 for HOG, SIFT etc.\n",
    "            return img.astype(np.uint8)\n",
    "        return img # Default return (uint8, RGB)\n",
    "    except Exception as e:\n",
    "        # print(f\"Error processing image {image_path} with CV2: {e}\")\n",
    "        return None\n",
    "\n",
    "# Choose one consistent preprocessor for feature extraction images\n",
    "image_preprocessor_for_features = preprocess_image_cv2\n",
    "\n",
    "# Function to use a subset of the dataframes (useful for quick tests or resource constraints)\n",
    "# The assignment mentions \"you can work with a subset of the dataset\"\n",
    "def get_subset_df(df, subset_fraction=0.1, random_state=42):\n",
    "    if df is None or df.empty or subset_fraction >= 1.0:\n",
    "        return df\n",
    "    # Stratified sampling to maintain class proportions in the subset\n",
    "    # Requires 'id' (numeric label) or 'label' (string label) column for stratification\n",
    "    group_col = 'id' if 'id' in df.columns else 'label'\n",
    "    \n",
    "    # Ensure frac is not too small to result in zero samples for some groups if not replacing\n",
    "    # A simple way is to ensure at least 1 sample per group if frac is very small, but pandas sample handles this.\n",
    "    return df.groupby(group_col, group_keys=False).apply(lambda x: x.sample(frac=subset_fraction, random_state=random_state, replace=False))\n",
    "\n",
    "\n",
    "# Example: If you want to use a subset (e.g., 10% for faster initial development)\n",
    "USE_SUBSET = False # Set to True to use a subset\n",
    "SUBSET_FRACTION = 0.05 # Example: 5% of the data for very quick tests.\n",
    "\n",
    "train_df_processed = train_df\n",
    "val_df_processed = val_df\n",
    "test_df_processed = test_df\n",
    "\n",
    "if USE_SUBSET and train_df is not None and not train_df.empty:\n",
    "    print(f\"\\nUsing a {SUBSET_FRACTION*100:.0f}% subset of the data for development...\")\n",
    "    train_df_processed = get_subset_df(train_df, SUBSET_FRACTION)\n",
    "    val_df_processed = get_subset_df(val_df, SUBSET_FRACTION)\n",
    "    test_df_processed = get_subset_df(test_df, SUBSET_FRACTION) \n",
    "    \n",
    "    print(f\"  New Training samples: {len(train_df_processed)}\")\n",
    "    print(f\"  New Validation samples: {len(val_df_processed)}\")\n",
    "    print(f\"  New Test samples: {len(test_df_processed)}\")\n",
    "else:\n",
    "    print(\"\\nUsing full prepared dataset splits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data Visualization (Extra)\n",
    "Visualize some sample images and the distribution of classes from our prepared DataFrames.\n",
    "\"Import and visualize the data in any aspects that you think it is beneficial for the reader's better understanding of the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_images_from_df(df, num_samples=10, title_prefix=\"\"):\n",
    "    if df is None or df.empty:\n",
    "        print(f\"{title_prefix} DataFrame is empty. Cannot visualize samples.\")\n",
    "        return\n",
    "    \n",
    "    # Ensure we don't try to sample more than available unique images\n",
    "    actual_num_samples = min(num_samples, len(df))\n",
    "    if actual_num_samples == 0: \n",
    "        print(f\"{title_prefix} DataFrame has no samples to visualize.\")\n",
    "        return\n",
    "        \n",
    "    sample_df = df.sample(actual_num_samples)\n",
    "    \n",
    "    plt.figure(figsize=(15, max(5, (actual_num_samples//5)*3) ))\n",
    "    for i, row in enumerate(sample_df.itertuples()):\n",
    "        img_path = row.filepath\n",
    "        label_str = row.label\n",
    "        try:\n",
    "            img = Image.open(img_path) # Use PIL for consistency with one of the preprocessors\n",
    "            plt.subplot( (actual_num_samples + 4) // 5 , 5, i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Class: {label_str}\", fontsize=8)\n",
    "            plt.axis('off')\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load image {img_path} for visualization: {e}\")\n",
    "    plt.suptitle(f\"{title_prefix} Sample Images from the Dataset\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "if train_df_processed is not None:\n",
    "    visualize_sample_images_from_df(train_df_processed, title_prefix=\"Training Set\")\n",
    "\n",
    "def plot_class_distribution_from_df(df, title=\"Class Distribution\"):\n",
    "    if df is None or df.empty:\n",
    "        print(f\"DataFrame for '{title}' is empty. Cannot plot class distribution.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.countplot(data=df, y='label', order = df['label'].value_counts().index, palette='viridis')\n",
    "    plt.title(title, fontsize=15)\n",
    "    plt.xlabel(\"Number of Samples\", fontsize=12)\n",
    "    plt.ylabel(\"Bird Species\", fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if train_df_processed is not None:\n",
    "    plot_class_distribution_from_df(train_df_processed, title=\"Training Set Class Distribution\")\n",
    "if val_df_processed is not None:\n",
    "    plot_class_distribution_from_df(val_df_processed, title=\"Validation Set Class Distribution\")\n",
    "if test_df_processed is not None:\n",
    "    plot_class_distribution_from_df(test_df_processed, title=\"Test Set Class Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Classification According to Feature Extraction\n",
    "\n",
    "In this part, we will extract features from the images and then apply basic Machine Learning (ML) algorithms. We need to try at least three feature extraction methodologies and at least three ML algorithms. Each extracted feature set will be tested with each model separately. Results and comments are required.\n",
    "\n",
    "**Chosen Feature Extraction Methods:**\n",
    "1.  **Color Histogram:** Captures color distribution.\n",
    "2.  **Histogram of Oriented Gradients (HOG):** Captures shape information by edge orientation.\n",
    "3.  **SIFT (Scale-Invariant Feature Transform) derived features (Aggregated):** Captures local keypoints, aggregated by averaging. (A full Bag of Visual Words would be more robust but is more complex to implement for this scope).\n",
    "\n",
    "**Chosen ML Algorithms:**\n",
    "1.  **Support Vector Machines (SVM)**\n",
    "2.  **Random Forest**\n",
    "3.  **Multilayer Perceptron (MLP)** (a simple neural network)\n",
    "\n",
    "Images will be loaded from the file paths in our DataFrames and preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for evaluating models\n",
    "part1_results_list = [] # To store results for comparison table\n",
    "\n",
    "def evaluate_and_log_model(model_name, feature_name, y_true, y_pred, class_names_list, results_accumulator):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # Use weighted average for precision, recall, F1 due to potential class imbalance if subsetting heavily\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Results for {model_name} with {feature_name}:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    results_accumulator.append({\n",
    "        'FeatureSet': feature_name,\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    # Ensure labels for confusion matrix are based on the unique values present in y_true and y_pred\n",
    "    # or all possible labels from label_encoder if y_true/y_pred might not cover all.\n",
    "    # For simplicity, using unique sorted labels from y_true.\n",
    "    # cm_labels = sorted(np.unique(np.concatenate((y_true, y_pred)))) \n",
    "    # Using all class_names ensures matrix size is consistent if some classes are missing in pred/true\n",
    "    cm_numeric_labels = np.arange(len(class_names_list)) \n",
    "\n",
    "    try:\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=cm_numeric_labels)\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=False, fmt='d', \n",
    "                    xticklabels=class_names_list, yticklabels=class_names_list)\n",
    "        plt.title(f\"Confusion Matrix: {model_name} with {feature_name}\", fontsize=14)\n",
    "        plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "        plt.ylabel(\"True Label\", fontsize=12)\n",
    "        plt.xticks(rotation=90, fontsize=8)\n",
    "        plt.yticks(rotation=0, fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except ValueError as ve_cm:\n",
    "        print(f\"Could not plot confusion matrix for {model_name} with {feature_name}: {ve_cm}\")\n",
    "        print(\"This might happen if y_true or y_pred contain labels not in class_names_list or if subsetting is extreme.\")\n",
    "\n",
    "    return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}\n",
    "\n",
    "def load_and_extract_features_from_df(df, feature_extraction_func, image_processor, limit=None):\n",
    "    \"\"\"Loads images from filepaths in a DataFrame, extracts features, and returns features and labels.\"\"\"\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    paths_to_process = df['filepath'].tolist()\n",
    "    corresponding_labels = df['id'].tolist() # Use numeric 'id' for labels\n",
    "\n",
    "    if limit is not None:\n",
    "        paths_to_process = paths_to_process[:limit]\n",
    "        corresponding_labels = corresponding_labels[:limit]\n",
    "        \n",
    "    processed_count = 0\n",
    "    for i, img_path in enumerate(paths_to_process):\n",
    "        if (i+1) % 200 == 0:\n",
    "            print(f\"  Processing image {i+1}/{len(paths_to_process)} for {feature_extraction_func.__name__}...\")\n",
    "        \n",
    "        # For feature extraction, usually we don't normalize to [0,1] for NN immediately\n",
    "        # HOG, SIFT often work on uint8 grayscale. Color Hist on uint8 RGB.\n",
    "        image = image_processor(img_path, target_size=TARGET_IMG_SIZE, for_feature_extraction=True)\n",
    "        \n",
    "        if image is not None:\n",
    "            feature_vector = feature_extraction_func(image)\n",
    "            if feature_vector is not None:\n",
    "                features_list.append(feature_vector)\n",
    "                labels_list.append(corresponding_labels[i])\n",
    "                processed_count += 1\n",
    "            #else: print(f\"    Feature extraction failed for {img_path}\")\n",
    "        #else: print(f\"    Image loading failed for {img_path}\")\n",
    "            \n",
    "    print(f\"  Successfully processed and extracted features for {processed_count}/{len(paths_to_process)} images.\")\n",
    "    if not features_list: # If no features were extracted\n",
    "        return np.array([]), np.array([])\n",
    "        \n",
    "    return np.array(features_list), np.array(labels_list)\n",
    "\n",
    "# Store all extracted features here for Part 1 & 2\n",
    "all_extracted_features = {} # Will be {'train': {feature_name: (X,y)}, 'val': ..., 'test': ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Feature Extraction: Color Histogram\n",
    "A color histogram represents the distribution of colors in an image. We compute a histogram for each channel (R, G, B) and concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, bins=32):\n",
    "    \"\"\"Extracts a concatenated color histogram for R, G, B channels. Image is uint8 RGB.\"\"\"\n",
    "    if image is None: return None\n",
    "    hist_features = []\n",
    "    for i in range(image.shape[2]): # Iterate over channels (R, G, B)\n",
    "        channel_hist = cv2.calcHist([image], [i], None, [bins], [0, 256])\n",
    "        cv2.normalize(channel_hist, channel_hist) # Normalize histogram\n",
    "        hist_features.extend(channel_hist.flatten())\n",
    "    return np.array(hist_features)\n",
    "\n",
    "feature_name_ch = 'ColorHistogram'\n",
    "all_extracted_features['train'] = {}\n",
    "all_extracted_features['val'] = {}\n",
    "all_extracted_features['test'] = {}\n",
    "\n",
    "if train_df_processed is not None and not train_df_processed.empty:\n",
    "    print(f\"Extracting {feature_name_ch} for Training set...\")\n",
    "    X_train_ch, y_train_ch = load_and_extract_features_from_df(train_df_processed, extract_color_histogram, image_preprocessor_for_features)\n",
    "    if X_train_ch.size > 0: all_extracted_features['train'][feature_name_ch] = (X_train_ch, y_train_ch)\n",
    "    else: print(f\"  No {feature_name_ch} features extracted for training set.\")\n",
    "\n",
    "    if val_df_processed is not None and not val_df_processed.empty:\n",
    "        print(f\"\\nExtracting {feature_name_ch} for Validation set...\")\n",
    "        X_val_ch, y_val_ch = load_and_extract_features_from_df(val_df_processed, extract_color_histogram, image_preprocessor_for_features)\n",
    "        if X_val_ch.size > 0: all_extracted_features['val'][feature_name_ch] = (X_val_ch, y_val_ch)\n",
    "        else: print(f\"  No {feature_name_ch} features extracted for validation set.\")\n",
    "\n",
    "    if test_df_processed is not None and not test_df_processed.empty:\n",
    "        print(f\"\\nExtracting {feature_name_ch} for Test set...\")\n",
    "        X_test_ch, y_test_ch = load_and_extract_features_from_df(test_df_processed, extract_color_histogram, image_preprocessor_for_features)\n",
    "        if X_test_ch.size > 0: all_extracted_features['test'][feature_name_ch] = (X_test_ch, y_test_ch)\n",
    "        else: print(f\"  No {feature_name_ch} features extracted for test set.\")\n",
    "\n",
    "    if X_train_ch.size > 0 : print(f\"\\n{feature_name_ch} feature shapes: Train: {X_train_ch.shape}, Val: {X_val_ch.shape if X_val_ch.size>0 else 'N/A'}, Test: {X_test_ch.shape if X_test_ch.size>0 else 'N/A'}\")\n",
    "else:\n",
    "    print(\"Skipping Color Histogram extraction as initial dataframes are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Feature Extraction: Histogram of Oriented Gradients (HOG)\n",
    "HOG features capture edge or gradient structure. We use `scikit-image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import color # exposure not used here directly\n",
    "\n",
    "def extract_hog_features(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), orientations=9):\n",
    "    \"\"\"Extracts HOG features from an image (expected uint8 RGB).\"\"\"\n",
    "    if image is None: return None\n",
    "    gray_image = color.rgb2gray(image) # skimage converts to float [0,1]\n",
    "    hog_features_vector = hog(gray_image, orientations=orientations,\n",
    "                       pixels_per_cell=pixels_per_cell,\n",
    "                       cells_per_block=cells_per_block,\n",
    "                       block_norm='L2-Hys',\n",
    "                       visualize=False,\n",
    "                       transform_sqrt=True)\n",
    "    return hog_features_vector\n",
    "\n",
    "feature_name_hog = 'HOG'\n",
    "if train_df_processed is not None and not train_df_processed.empty:\n",
    "    print(f\"Extracting {feature_name_hog} for Training set...\")\n",
    "    X_train_hog, y_train_hog = load_and_extract_features_from_df(train_df_processed, extract_hog_features, image_preprocessor_for_features)\n",
    "    if X_train_hog.size > 0: all_extracted_features['train'][feature_name_hog] = (X_train_hog, y_train_hog)\n",
    "    else: print(f\"  No {feature_name_hog} features extracted for training set.\")\n",
    "\n",
    "    if val_df_processed is not None and not val_df_processed.empty:\n",
    "        print(f\"\\nExtracting {feature_name_hog} for Validation set...\")\n",
    "        X_val_hog, y_val_hog = load_and_extract_features_from_df(val_df_processed, extract_hog_features, image_preprocessor_for_features)\n",
    "        if X_val_hog.size > 0: all_extracted_features['val'][feature_name_hog] = (X_val_hog, y_val_hog)\n",
    "        else: print(f\"  No {feature_name_hog} features extracted for validation set.\")\n",
    "\n",
    "    if test_df_processed is not None and not test_df_processed.empty:\n",
    "        print(f\"\\nExtracting {feature_name_hog} for Test set...\")\n",
    "        X_test_hog, y_test_hog = load_and_extract_features_from_df(test_df_processed, extract_hog_features, image_preprocessor_for_features)\n",
    "        if X_test_hog.size > 0: all_extracted_features['test'][feature_name_hog] = (X_test_hog, y_test_hog)\n",
    "        else: print(f\"  No {feature_name_hog} features extracted for test set.\")\n",
    "\n",
    "    if X_train_hog.size > 0 : print(f\"\\n{feature_name_hog} feature shapes: Train: {X_train_hog.shape}, Val: {X_val_hog.shape if X_val_hog.size>0 else 'N/A'}, Test: {X_test_hog.shape if X_test_hog.size>0 else 'N/A'}\")\n",
    "else:\n",
    "    print(\"Skipping HOG extraction as initial dataframes are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Feature Extraction: SIFT (Aggregated)\n",
    "SIFT detects local features. We'll aggregate descriptors (e.g., by averaging) for a fixed-size vector.\n",
    "Ensure `opencv-contrib-python` is installed for SIFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SIFT detector\n",
    "sift_detector = None\n",
    "try:\n",
    "    sift_detector = cv2.SIFT_create()\n",
    "except AttributeError:\n",
    "    print(\"cv2.SIFT_create() not found. Ensure 'opencv-contrib-python' is installed.\")\n",
    "    # Fallback for older OpenCV versions (might not be available/work)\n",
    "    # try:\n",
    "    #     sift_detector = cv2.xfeatures2d.SIFT_create()\n",
    "    # except AttributeError:\n",
    "    #     print(\"cv2.xfeatures2d.SIFT_create() also not found. SIFT features cannot be extracted.\")\n",
    "    #     sift_detector = None\n",
    "if sift_detector is not None:\n",
    "    print(\"SIFT detector initialized successfully.\")\n",
    "\n",
    "MAX_KEYPOINTS_SIFT = 100 # Limit keypoints per image if using aggregation\n",
    "SIFT_DESCRIPTOR_SIZE = 128\n",
    "\n",
    "def extract_sift_features_aggregated(image):\n",
    "    \"\"\"Extracts SIFT descriptors and aggregates them by averaging. Image is uint8 RGB.\"\"\"\n",
    "    if image is None or sift_detector is None: return np.zeros(SIFT_DESCRIPTOR_SIZE) # Return zero vector if no image/detector\n",
    "    \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # SIFT works on grayscale\n",
    "    # Image should already be uint8 from image_preprocessor_for_features\n",
    "\n",
    "    keypoints, descriptors = sift_detector.detectAndCompute(gray_image, None)\n",
    "    \n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        return np.zeros(SIFT_DESCRIPTOR_SIZE) # Return zero vector if no descriptors found\n",
    "\n",
    "    # Optional: Limit number of descriptors (e.g., take top N by response, or just first N)\n",
    "    # descriptors = descriptors[:MAX_KEYPOINTS_SIFT]\n",
    "        \n",
    "    # Aggregate descriptors: simple averaging\n",
    "    aggregated_descriptor = np.mean(descriptors, axis=0)\n",
    "    return aggregated_descriptor.flatten()\n",
    "\n",
    "feature_name_sift = 'SIFT_Aggregated'\n",
    "if sift_detector is not None and train_df_processed is not None and not train_df_processed.empty:\n",
    "    print(f\"Extracting {feature_name_sift} for Training set...\")\n",
    "    X_train_sift, y_train_sift = load_and_extract_features_from_df(train_df_processed, extract_sift_features_aggregated, image_preprocessor_for_features)\n",
    "    if X_train_sift.size > 0: all_extracted_features['train'][feature_name_sift] = (X_train_sift, y_train_sift)\n",
    "    else: print(f\"  No {feature_name_sift} features extracted for training set.\")\n",
    "\n",
    "    if val_df_processed is not None and not val_df_processed.empty:\n",
    "        print(f\"\\nExtracting {feature_name_sift} for Validation set...\")\n",
    "        X_val_sift, y_val_sift = load_and_extract_features_from_df(val_df_processed, extract_sift_features_aggregated, image_preprocessor_for_features)\n",
    "        if X_val_sift.size > 0: all_extracted_features['val'][feature_name_sift] = (X_val_sift, y_val_sift)\n",
    "        else: print(f\"  No {feature_name_sift} features extracted for validation set.\")\n",
    "\n",
    "    if test_df_processed is not None and not test_df_processed.empty:\n",
    "        print(f\"\\nExtracting {feature_name_sift} for Test set...\")\n",
    "        X_test_sift, y_test_sift = load_and_extract_features_from_df(test_df_processed, extract_sift_features_aggregated, image_preprocessor_for_features)\n",
    "        if X_test_sift.size > 0: all_extracted_features['test'][feature_name_sift] = (X_test_sift, y_test_sift)\n",
    "        else: print(f\"  No {feature_name_sift} features extracted for test set.\")\n",
    "\n",
    "    if X_train_sift.size > 0 : print(f\"\\n{feature_name_sift} feature shapes: Train: {X_train_sift.shape}, Val: {X_val_sift.shape if X_val_sift.size>0 else 'N/A'}, Test: {X_test_sift.shape if X_test_sift.size>0 else 'N/A'}\")\n",
    "else:\n",
    "    print(\"Skipping SIFT Aggregated extraction as SIFT detector is not available or initial dataframes are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Training Machine Learning Models\n",
    "We train SVM, Random Forest, and MLP on each extracted feature set. Features are scaled for SVM and MLP using a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "models_to_try_part1 = {\n",
    "    \"SVM\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svc', SVC(kernel='rbf', C=1.0, probability=True, random_state=42, class_weight='balanced'))\n",
    "    ]),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced'),\n",
    "    # MLP parameters: increased max_iter, early stopping for convergence. Adjust hidden_layer_sizes as needed.\n",
    "    \"MLP\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('mlp', MLPClassifier(hidden_layer_sizes=(256, 128), max_iter=500, alpha=0.001, \n",
    "                               solver='adam', learning_rate_init=0.001, learning_rate='adaptive',\n",
    "                               random_state=42, early_stopping=True, n_iter_no_change=20, verbose=False))\n",
    "    ])\n",
    "}\n",
    "\n",
    "if not all_extracted_features.get('train') or not all_extracted_features['train']:\n",
    "    print(\"No features were successfully extracted for the training set. Cannot train Part 1 models.\")\n",
    "else:\n",
    "    for feature_name_iter, (X_train_feat, y_train_target) in all_extracted_features['train'].items():\n",
    "        print(f\"\\n--- Training models on Feature Set: {feature_name_iter} ---\")\n",
    "        print(f\"Training data shape: X: {X_train_feat.shape}, y: {y_train_target.shape}\")\n",
    "\n",
    "        if feature_name_iter not in all_extracted_features.get('test', {}) or all_extracted_features['test'][feature_name_iter][0].size == 0:\n",
    "            print(f\"  Test features for {feature_name_iter} not found or empty. Skipping model training for this feature set.\")\n",
    "            continue\n",
    "            \n",
    "        X_test_feat, y_test_target = all_extracted_features['test'][feature_name_iter]\n",
    "        print(f\"Test data shape: X: {X_test_feat.shape}, y: {y_test_target.shape}\")\n",
    "\n",
    "        if X_train_feat.ndim == 1: X_train_feat = X_train_feat.reshape(-1, 1)\n",
    "        if X_test_feat.ndim == 1: X_test_feat = X_test_feat.reshape(-1, 1)\n",
    "\n",
    "        if X_train_feat.shape[0] == 0 or X_test_feat.shape[0] == 0 or y_train_target.shape[0] == 0 or y_test_target.shape[0] == 0:\n",
    "            print(f\"  Skipping {feature_name_iter} due to empty training/test features or labels.\")\n",
    "            continue\n",
    "        \n",
    "        for model_name_iter, model_pipeline in models_to_try_part1.items():\n",
    "            print(f\"  Training {model_name_iter} with {feature_name_iter}...\")\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                model_pipeline.fit(X_train_feat, y_train_target)\n",
    "                end_time = time.time()\n",
    "                print(f\"    Training {model_name_iter} took {end_time - start_time:.2f} seconds.\")\n",
    "                \n",
    "                # Evaluate on the TEST set for final performance\n",
    "                y_pred_test = model_pipeline.predict(X_test_feat)\n",
    "                \n",
    "                print(f\"    Test Set Evaluation for {model_name_iter} with {feature_name_iter}:\")\n",
    "                evaluate_and_log_model(model_name_iter, feature_name_iter, y_test_target, y_pred_test, class_names, part1_results_list)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ERROR training/evaluating {model_name_iter} with {feature_name_iter}: {e}\")\n",
    "\n",
    "# Display summary of Part 1 results\n",
    "if part1_results_list:\n",
    "    part1_results_df = pd.DataFrame(part1_results_list)\n",
    "    print(\"\\n\\n--- Summary of Part 1 Results (Test Set) ---\")\n",
    "    print(part1_results_df.to_string())\n",
    "else:\n",
    "    print(\"No models were trained in Part 1, or no results were collected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Comments on Part 1 Results\n",
    "*(This section is for your analysis. Fill this in based on the actual results you obtain after running the code. Commenting is as important as experimenting.)*\n",
    "\n",
    "* **Color Histogram:**\n",
    "    * Performance with SVM: *(Accuracy, Precision, Recall, F1)*\n",
    "    * Performance with Random Forest: *(Accuracy, Precision, Recall, F1)*\n",
    "    * Performance with MLP: *(Accuracy, Precision, Recall, F1)*\n",
    "    * *Comments:* How well did color histograms perform? Were there significant differences between the models? Why might this be the case? What are the limitations of color histograms for bird classification?\n",
    "\n",
    "* **HOG Features:**\n",
    "    * Performance with SVM: *(Accuracy, Precision, Recall, F1)*\n",
    "    * Performance with Random Forest: *(Accuracy, Precision, Recall, F1)*\n",
    "    * Performance with MLP: *(Accuracy, Precision, Recall, F1)*\n",
    "    * *Comments:* Did HOG features improve results compared to color histograms? HOG captures shape; how relevant is this for distinguishing bird species with subtle differences?\n",
    "\n",
    "* **SIFT (Aggregated) Features:**\n",
    "    * Performance with SVM: *(Accuracy, Precision, Recall, F1)*\n",
    "    * Performance with Random Forest: *(Accuracy, Precision, Recall, F1)*\n",
    "    * Performance with MLP: *(Accuracy, Precision, Recall, F1)*\n",
    "    * *Comments:* How did the simplified SIFT approach perform? What are the drawbacks of simple aggregation (e.g., averaging)? How might a full Bag of Visual Words (BoVW) model potentially change performance?\n",
    "\n",
    "* **Overall Comparison for Part 1:**\n",
    "    * Which feature extraction method generally performed best?\n",
    "    * Which ML algorithm was most effective with these traditional features?\n",
    "    * Were results satisfactory for a 25-class problem? Discuss limitations of these feature-based approaches for complex image tasks.\n",
    "    * Discuss any computational challenges (e.g., time for SIFT, feature vector sizes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Principal Component Analysis and Feature Selection\n",
    "\n",
    "Apply PCA and a feature selection method (that eliminates features) to all features extracted in Part 1. Then, try the same ML algorithms as in Part 1. Compare results with Part 1 and within Part 2 approaches.\n",
    "\n",
    "**Chosen Feature Selection Method (Elimination):**\n",
    "* **SelectKBest with `f_classif`:** Selects features with the highest ANOVA F-values between label/feature for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "part2_results_list = []\n",
    "N_COMPONENTS_PCA = 0.95 # Keep components explaining 95% of variance, or set an integer\n",
    "# For SelectKBest, k can be a fixed number or a percentage. Let's try 50% of original features or a fixed moderate number.\n",
    "# SIFT aggregated has 128 features, HOG can be large. ColorHist is bins*3.\n",
    "\n",
    "if not all_extracted_features.get('train') or not all_extracted_features['train']:\n",
    "    print(\"No features available from Part 1. Skipping Part 2.\")\n",
    "else:\n",
    "    for feature_name_iter, (X_train_orig, y_train_orig) in all_extracted_features['train'].items():\n",
    "        print(f\"\\n--- Processing Part 2 for Feature Set: {feature_name_iter} ---\")\n",
    "        if X_train_orig.size == 0: \n",
    "            print(f\"  Skipping {feature_name_iter} as original training features are empty.\")\n",
    "            continue\n",
    "\n",
    "        # Ensure corresponding val and test sets exist\n",
    "        if feature_name_iter not in all_extracted_features.get('val', {}) or all_extracted_features['val'][feature_name_iter][0].size == 0 or \\\n",
    "           feature_name_iter not in all_extracted_features.get('test', {}) or all_extracted_features['test'][feature_name_iter][0].size == 0:\n",
    "            print(f\"  Skipping {feature_name_iter} due to missing/empty val/test original features.\")\n",
    "            continue\n",
    "        \n",
    "        X_val_orig, y_val_orig = all_extracted_features['val'][feature_name_iter]\n",
    "        X_test_orig, y_test_orig = all_extracted_features['test'][feature_name_iter]\n",
    "\n",
    "        # --- 2.1 PCA ---\n",
    "        print(f\"  Applying PCA to {feature_name_iter}...\")\n",
    "        # Scale data before PCA\n",
    "        scaler_pca = StandardScaler()\n",
    "        X_train_scaled_pca = scaler_pca.fit_transform(X_train_orig)\n",
    "        X_val_scaled_pca = scaler_pca.transform(X_val_orig) # Use train's scaler\n",
    "        X_test_scaled_pca = scaler_pca.transform(X_test_orig)  # Use train's scaler\n",
    "\n",
    "        # Determine n_components for PCA if it's a float (variance explained)\n",
    "        # Ensure n_components is less than min(n_samples, n_features)\n",
    "        current_n_components_pca = N_COMPONENTS_PCA\n",
    "        if isinstance(N_COMPONENTS_PCA, float) and N_COMPONENTS_PCA < 1.0:\n",
    "            # If it's a float, it's variance. It will pick components.\n",
    "            pass \n",
    "        elif isinstance(N_COMPONENTS_PCA, int):\n",
    "             current_n_components_pca = min(N_COMPONENTS_PCA, X_train_scaled_pca.shape[0], X_train_scaled_pca.shape[1])\n",
    "        else: # Default to a safe number if not float or int\n",
    "            current_n_components_pca = min(100, X_train_scaled_pca.shape[0], X_train_scaled_pca.shape[1])\n",
    "        if current_n_components_pca <=0: current_n_components_pca = 1 # must be at least 1 if int specified became 0\n",
    "\n",
    "        if X_train_scaled_pca.shape[1] < 2: # Not enough features for PCA reduction in some cases\n",
    "            print(f\"    Skipping PCA for {feature_name_iter} as it has < 2 features ({X_train_scaled_pca.shape[1]}). Using scaled original.\")\n",
    "            X_train_pca, X_val_pca, X_test_pca = X_train_scaled_pca, X_val_scaled_pca, X_test_scaled_pca\n",
    "        else:\n",
    "            # If current_n_components_pca (int) is > features, PCA will use n_features\n",
    "            if isinstance(current_n_components_pca, int) and current_n_components_pca > X_train_scaled_pca.shape[1]:\n",
    "                current_n_components_pca = X_train_scaled_pca.shape[1]\n",
    "            \n",
    "            pca = PCA(n_components=current_n_components_pca, random_state=42)\n",
    "            try:\n",
    "                X_train_pca = pca.fit_transform(X_train_scaled_pca)\n",
    "                X_val_pca = pca.transform(X_val_scaled_pca)\n",
    "                X_test_pca = pca.transform(X_test_scaled_pca)\n",
    "                print(f\"    PCA applied. Original dim: {X_train_scaled_pca.shape[1]}, Reduced dim: {X_train_pca.shape[1]}\")\n",
    "            except ValueError as e_pca:\n",
    "                print(f\"    Error applying PCA for {feature_name_iter}: {e_pca}. Using scaled original features.\")\n",
    "                X_train_pca, X_val_pca, X_test_pca = X_train_scaled_pca, X_val_scaled_pca, X_test_scaled_pca\n",
    "        \n",
    "        # Train models on PCA-transformed features\n",
    "        if X_train_pca.size > 0:\n",
    "            for model_name_iter, model_pipeline in models_to_try_part1.items():\n",
    "                print(f\"    Training {model_name_iter} with {feature_name_iter}_PCA...\")\n",
    "                start_time = time.time()\n",
    "                try:\n",
    "                    model_pipeline.fit(X_train_pca, y_train_orig)\n",
    "                    end_time = time.time()\n",
    "                    print(f\"      Training {model_name_iter} took {end_time - start_time:.2f} seconds.\")\n",
    "                    y_pred_pca = model_pipeline.predict(X_test_pca)\n",
    "                    evaluate_and_log_model(model_name_iter, f\"{feature_name_iter}_PCA\", y_test_orig, y_pred_pca, class_names, part2_results_list)\n",
    "                except Exception as e:\n",
    "                    print(f\"      ERROR training/evaluating {model_name_iter} with {feature_name_iter}_PCA: {e}\")\n",
    "        else:\n",
    "            print(f\"    Skipping model training for {feature_name_iter}_PCA due to empty PCA features.\")\n",
    "\n",
    "        # --- 2.2 Feature Selection (SelectKBest) ---\n",
    "        print(f\"\\n  Applying SelectKBest to {feature_name_iter}...\")\n",
    "        num_original_features = X_train_orig.shape[1]\n",
    "        if num_original_features < 2:\n",
    "            print(f\"    Skipping SelectKBest for {feature_name_iter} as it has < 2 features ({num_original_features}). Using original.\")\n",
    "            X_train_skb, X_val_skb, X_test_skb = X_train_orig, X_val_orig, X_test_orig\n",
    "        else:\n",
    "            k_features = max(1, min(num_original_features // 2, 100)) # e.g., 50% of features, capped at 100, at least 1\n",
    "            if num_original_features <= k_features: # if already few features, use all\n",
    "                print(f\"    Number of features ({num_original_features}) is less than or equal to k={k_features}. Using all original features for SKB step.\")\n",
    "                X_train_skb, X_val_skb, X_test_skb = X_train_orig, X_val_orig, X_test_orig \n",
    "            else:\n",
    "                selector_skb = SelectKBest(score_func=f_classif, k=k_features)\n",
    "                try:\n",
    "                    X_train_skb = selector_skb.fit_transform(X_train_orig, y_train_orig)\n",
    "                    X_val_skb = selector_skb.transform(X_val_orig)\n",
    "                    X_test_skb = selector_skb.transform(X_test_orig)\n",
    "                    print(f\"    SelectKBest applied. Original dim: {num_original_features}, Reduced dim: {X_train_skb.shape[1]}\")\n",
    "                except ValueError as e_skb:\n",
    "                    print(f\"    Error applying SelectKBest for {feature_name_iter}: {e_skb}. Using original features.\")\n",
    "                    X_train_skb, X_val_skb, X_test_skb = X_train_orig, X_val_orig, X_test_orig\n",
    "\n",
    "        # Train models on SelectKBest-transformed features\n",
    "        if X_train_skb.size > 0:\n",
    "            for model_name_iter, model_pipeline in models_to_try_part1.items():\n",
    "                print(f\"    Training {model_name_iter} with {feature_name_iter}_SelectKBest...\")\n",
    "                start_time = time.time()\n",
    "                try:\n",
    "                    model_pipeline.fit(X_train_skb, y_train_orig)\n",
    "                    end_time = time.time()\n",
    "                    print(f\"      Training {model_name_iter} took {end_time - start_time:.2f} seconds.\")\n",
    "                    y_pred_skb = model_pipeline.predict(X_test_skb)\n",
    "                    evaluate_and_log_model(model_name_iter, f\"{feature_name_iter}_SelectKBest\", y_test_orig, y_pred_skb, class_names, part2_results_list)\n",
    "                except Exception as e:\n",
    "                    print(f\"      ERROR training/evaluating {model_name_iter} with {feature_name_iter}_SelectKBest: {e}\")\n",
    "        else:\n",
    "            print(f\"    Skipping model training for {feature_name_iter}_SelectKBest due to empty features.\")\n",
    "\n",
    "# Display summary of Part 2 results\n",
    "if part2_results_list:\n",
    "    part2_results_df = pd.DataFrame(part2_results_list)\n",
    "    print(\"\\n\\n--- Summary of Part 2 Results (Test Set) ---\")\n",
    "    print(part2_results_df.to_string())\n",
    "else:\n",
    "    print(\"No models were trained in Part 2, or no results were collected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Comments on Part 2 Results\n",
    "*(This section is for your analysis. Fill this in based on actual results. Compare results of these two approaches (PCA, SelectKBest) with each other and with Part 1.)*\n",
    "\n",
    "* **PCA Performance:**\n",
    "    * For Color Histograms + PCA: *(Discuss model performances)*\n",
    "    * For HOG + PCA: *(Discuss model performances)*\n",
    "    * For SIFT (Aggregated) + PCA: *(Discuss model performances)*\n",
    "    * *Comments:* How did PCA affect the performance for each feature type and model? Did dimensionality reduction help improve speed or accuracy, or did it hurt? How many principal components were typically selected and how much variance did they explain?\n",
    "\n",
    "* **SelectKBest Performance:**\n",
    "    * For Color Histograms + SelectKBest: *(Discuss model performances)*\n",
    "    * For HOG + SelectKBest: *(Discuss model performances)*\n",
    "    * For SIFT (Aggregated) + SelectKBest: *(Discuss model performances)*\n",
    "    * *Comments:* How did SelectKBest perform compared to PCA and raw features? Did eliminating features improve results or training time? What was the impact of the chosen `k` value?\n",
    "\n",
    "* **Overall Comparison for Part 2:**\n",
    "    * Compare PCA vs. SelectKBest: Which method was generally more beneficial or detrimental?\n",
    "    * Compare Part 2 (PCA/SelectKBest) vs. Part 1 (Raw Features): Did these dimensionality reduction/feature selection techniques lead to better overall models in terms of accuracy, F1-score, or training efficiency? Explain your reasoning.\n",
    "    * Discuss any changes in model behavior or sensitivity after applying these techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Fine-Tuning Pretrained CNN Models\n",
    "\n",
    "Select at least three well-known pretrained CNN models and fine-tune them for the bird dataset. Report results, loss graphs, and decide where to stop training.\n",
    "\n",
    "**Chosen Pretrained Models:**\n",
    "1.  **VGG16**\n",
    "2.  **ResNet50**\n",
    "3.  **EfficientNetB0** (Known for good balance of accuracy and efficiency)\n",
    "\n",
    "We will use `ImageDataGenerator.flow_from_dataframe` to feed images from our prepared DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_CNN = 32 # Adjust based on your GPU memory\n",
    "NUM_CLASSES = len(class_names) if class_names else 25 # Fallback to 25 if class_names not loaded\n",
    "EPOCHS_FT_HEAD = 25       # Initial epochs for fine-tuning the head, can be adjusted\n",
    "EPOCHS_FT_FULL = 15  # Epochs for fine-tuning more layers, can be adjusted\n",
    "\n",
    "train_generator_cnn = None\n",
    "validation_generator_cnn = None\n",
    "test_generator_cnn = None\n",
    "\n",
    "if train_df_processed is None or train_df_processed.empty or val_df_processed is None or val_df_processed.empty:\n",
    "    print(\"Training or validation DataFrame is missing/empty. Cannot proceed with CNN training.\")\n",
    "else:\n",
    "    # Data Augmentation for training images\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, # Rescale pixel values from [0,255] to [0,1]\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # For validation and test, only rescaling\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    common_flow_params = {\n",
    "        'x_col': 'filepath',\n",
    "        'y_col': 'label', # Use string labels, classes will be inferred or can be set by class_names\n",
    "        'target_size': TARGET_IMG_SIZE,\n",
    "        'batch_size': BATCH_SIZE_CNN,\n",
    "        'class_mode': 'categorical', # for multi-class classification\n",
    "        'seed': 42,\n",
    "        'classes': class_names # Ensure consistent class ordering\n",
    "    }\n",
    "    try:\n",
    "        train_generator_cnn = train_datagen.flow_from_dataframe(\n",
    "            dataframe=train_df_processed,\n",
    "            shuffle=True,\n",
    "            **common_flow_params\n",
    "        )\n",
    "\n",
    "        validation_generator_cnn = val_test_datagen.flow_from_dataframe(\n",
    "            dataframe=val_df_processed,\n",
    "            shuffle=False, # No need to shuffle validation data\n",
    "            **common_flow_params\n",
    "        )\n",
    "        \n",
    "        if test_df_processed is not None and not test_df_processed.empty:\n",
    "            test_generator_cnn = val_test_datagen.flow_from_dataframe(\n",
    "                dataframe=test_df_processed,\n",
    "                shuffle=False,\n",
    "                **common_flow_params\n",
    "            )\n",
    "            print(f\"Test generator created with {test_generator_cnn.n} samples.\")\n",
    "        else:\n",
    "            print(\"Test DataFrame is empty or None. Test generator not created.\")\n",
    "\n",
    "        print(f\"Train generator created with {train_generator_cnn.n} samples, {train_generator_cnn.num_classes} classes.\")\n",
    "        print(f\"Validation generator created with {validation_generator_cnn.n} samples, {validation_generator_cnn.num_classes} classes.\")\n",
    "\n",
    "    except Exception as e_gen:\n",
    "        print(f\"Error creating Keras data generators: {e_gen}\")\n",
    "        print(\"This might be due to empty dataframes or issues with file paths.\")\n",
    "        train_generator_cnn = None \n",
    "        validation_generator_cnn = None\n",
    "        test_generator_cnn = None\n",
    "\n",
    "def plot_training_history(history, model_name_str):\n",
    "    \"\"\"Plots accuracy and loss for training and validation sets.\"\"\"\n",
    "    if not history or not history.history:\n",
    "        print(f\"No history data to plot for {model_name_str}.\")\n",
    "        return\n",
    "        \n",
    "    acc = history.history.get('accuracy', [])\n",
    "    val_acc = history.history.get('val_accuracy', [])\n",
    "    loss = history.history.get('loss', [])\n",
    "    val_loss = history.history.get('val_loss', [])\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(f'{model_name_str} - Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'{model_name_str} - Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "part3_results_list = []\n",
    "cnn_model_histories = {} # To store history objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Fine-tuning VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_generator_cnn is not None and validation_generator_cnn is not None and NUM_CLASSES > 0:\n",
    "    base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    base_model_vgg16.trainable = False # Freeze base model initially\n",
    "\n",
    "    model_vgg16 = Sequential([\n",
    "        base_model_vgg16,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu', kernel_initializer='he_normal'),\n",
    "        Dropout(0.5),\n",
    "        Dense(NUM_CLASSES, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "    ], name=\"VGG16_FineTuned\")\n",
    "\n",
    "    model_vgg16.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    print(\"VGG16 Model Summary (Head Training):\")\n",
    "    model_vgg16.summary()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "    # Train the head\n",
    "    print(\"\\nTraining VGG16 head...\")\n",
    "    history_vgg16_head = model_vgg16.fit(\n",
    "        train_generator_cnn,\n",
    "        epochs=EPOCHS_FT_HEAD,\n",
    "        validation_data=validation_generator_cnn,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    cnn_model_histories['VGG16_Head'] = history_vgg16_head\n",
    "    plot_training_history(history_vgg16_head, \"VGG16 (Head Fine-Tuned)\")\n",
    "\n",
    "    # Unfreeze some layers of VGG16 for further fine-tuning\n",
    "    base_model_vgg16.trainable = True\n",
    "    fine_tune_at = 15 # VGG16 has 19 layers in base (block5_conv1 is layer index 14, so unfreeze from here)\n",
    "    for layer in base_model_vgg16.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model_vgg16.compile(optimizer=Adam(learning_rate=1e-5), # Lower learning rate for full fine-tuning\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    print(\"\\nVGG16 Model Summary (Full Fine-Tuning):\")\n",
    "    # model_vgg16.summary() # Can be very long, optional\n",
    "\n",
    "    print(\"\\nFine-tuning VGG16 (more layers)...\")\n",
    "    # Calculate initial_epoch correctly for continued training\n",
    "    initial_epoch_full_ft = 0\n",
    "    if history_vgg16_head and history_vgg16_head.epoch:\n",
    "        initial_epoch_full_ft = history_vgg16_head.epoch[-1] + 1\n",
    "        \n",
    "    history_vgg16_full = model_vgg16.fit(\n",
    "        train_generator_cnn,\n",
    "        epochs=initial_epoch_full_ft + EPOCHS_FT_FULL,\n",
    "        initial_epoch=initial_epoch_full_ft,\n",
    "        validation_data=validation_generator_cnn,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    cnn_model_histories['VGG16_FullFT'] = history_vgg16_full\n",
    "    plot_training_history(history_vgg16_full, \"VGG16 (Full Fine-Tuned)\")\n",
    "    \n",
    "    # Evaluate VGG16\n",
    "    if test_generator_cnn:\n",
    "        print(\"\\nEvaluating VGG16 (Fine-Tuned) on Test Set...\")\n",
    "        vgg16_loss, vgg16_accuracy = model_vgg16.evaluate(test_generator_cnn)\n",
    "        print(f\"VGG16 Test Accuracy: {vgg16_accuracy:.4f}, Test Loss: {vgg16_loss:.4f}\")\n",
    "        y_pred_vgg16_probs = model_vgg16.predict(test_generator_cnn)\n",
    "        y_pred_vgg16 = np.argmax(y_pred_vgg16_probs, axis=1)\n",
    "        evaluate_and_log_model(\"VGG16_FineTuned\", \"CNN_TransferLearn\", test_generator_cnn.classes, y_pred_vgg16, class_names, part3_results_list)\n",
    "    else:\n",
    "        print(\"Test generator not available. Skipping VGG16 evaluation.\")\n",
    "else:\n",
    "    print(\"Skipping VGG16 fine-tuning as data generators or class info are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fine-tuning ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_generator_cnn is not None and validation_generator_cnn is not None and NUM_CLASSES > 0:\n",
    "    base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    base_model_resnet50.trainable = False \n",
    "\n",
    "    model_resnet50 = Sequential([\n",
    "        base_model_resnet50,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu', kernel_initializer='he_normal'),\n",
    "        BatchNormalization(), \n",
    "        Dropout(0.5),\n",
    "        Dense(NUM_CLASSES, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "    ], name=\"ResNet50_FineTuned\")\n",
    "\n",
    "    model_resnet50.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    print(\"ResNet50 Model Summary (Head Training):\")\n",
    "    model_resnet50.summary()\n",
    "\n",
    "    early_stopping_resnet = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "    print(\"\\nTraining ResNet50 head...\")\n",
    "    history_resnet50_head = model_resnet50.fit(\n",
    "        train_generator_cnn,\n",
    "        epochs=EPOCHS_FT_HEAD,\n",
    "        validation_data=validation_generator_cnn,\n",
    "        callbacks=[early_stopping_resnet]\n",
    "    )\n",
    "    cnn_model_histories['ResNet50_Head'] = history_resnet50_head\n",
    "    plot_training_history(history_resnet50_head, \"ResNet50 (Head Fine-Tuned)\")\n",
    "\n",
    "    # Unfreeze some layers of ResNet50\n",
    "    base_model_resnet50.trainable = True\n",
    "    fine_tune_at_resnet = 140 # Example: unfreeze layers from conv5_block1_out onwards (ResNet50 has ~170 layers)\n",
    "    for layer in base_model_resnet50.layers[:fine_tune_at_resnet]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model_resnet50.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "    # print(\"\\nResNet50 Model Summary (Full Fine-Tuning):\") # Optional: Can be very long\n",
    "    # model_resnet50.summary()\n",
    "\n",
    "    print(\"\\nFine-tuning ResNet50 (more layers)...\")\n",
    "    initial_epoch_full_ft_resnet = 0\n",
    "    if history_resnet50_head and history_resnet50_head.epoch:\n",
    "        initial_epoch_full_ft_resnet = history_resnet50_head.epoch[-1] + 1\n",
    "        \n",
    "    history_resnet50_full = model_resnet50.fit(\n",
    "        train_generator_cnn,\n",
    "        epochs=initial_epoch_full_ft_resnet + EPOCHS_FT_FULL,\n",
    "        initial_epoch=initial_epoch_full_ft_resnet,\n",
    "        validation_data=validation_generator_cnn,\n",
    "        callbacks=[early_stopping_resnet]\n",
    "    )\n",
    "    cnn_model_histories['ResNet50_FullFT'] = history_resnet50_full\n",
    "    plot_training_history(history_resnet50_full, \"ResNet50 (Full Fine-Tuned)\")\n",
    "\n",
    "    if test_generator_cnn:\n",
    "        print(\"\\nEvaluating ResNet50 (Fine-Tuned) on Test Set...\")\n",
    "        resnet50_loss, resnet50_accuracy = model_resnet50.evaluate(test_generator_cnn)\n",
    "        print(f\"ResNet50 Test Accuracy: {resnet50_accuracy:.4f}, Test Loss: {resnet50_loss:.4f}\")\n",
    "        y_pred_resnet50_probs = model_resnet50.predict(test_generator_cnn)\n",
    "        y_pred_resnet50 = np.argmax(y_pred_resnet50_probs, axis=1)\n",
    "        evaluate_and_log_model(\"ResNet50_FineTuned\", \"CNN_TransferLearn\", test_generator_cnn.classes, y_pred_resnet50, class_names, part3_results_list)\n",
    "    else:\n",
    "        print(\"Test generator not available. Skipping ResNet50 evaluation.\")\n",
    "else:\n",
    "    print(\"Skipping ResNet50 fine-tuning as data generators or class info are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Fine-tuning EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_generator_cnn is not None and validation_generator_cnn is not None and NUM_CLASSES > 0:\n",
    "    base_model_effnet = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    base_model_effnet.trainable = False\n",
    "\n",
    "    model_effnet = Sequential([\n",
    "        base_model_effnet,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu', kernel_initializer='he_normal'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(NUM_CLASSES, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "    ], name=\"EfficientNetB0_FineTuned\")\n",
    "\n",
    "    model_effnet.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                         loss='categorical_crossentropy',\n",
    "                         metrics=['accuracy'])\n",
    "    print(\"EfficientNetB0 Model Summary (Head Training):\")\n",
    "    model_effnet.summary()\n",
    "\n",
    "    early_stopping_effnet = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "    print(\"\\nTraining EfficientNetB0 head...\")\n",
    "    history_effnet_head = model_effnet.fit(\n",
    "        train_generator_cnn,\n",
    "        epochs=EPOCHS_FT_HEAD,\n",
    "        validation_data=validation_generator_cnn,\n",
    "        callbacks=[early_stopping_effnet]\n",
    "    )\n",
    "    cnn_model_histories['EfficientNetB0_Head'] = history_effnet_head\n",
    "    plot_training_history(history_effnet_head, \"EfficientNetB0 (Head Fine-Tuned)\")\n",
    "\n",
    "    # Unfreeze some layers of EfficientNetB0\n",
    "    base_model_effnet.trainable = True \n",
    "    fine_tune_at_effnet = -20 # Unfreeze last 20 layers as an example for EfficientNet. Adjust as needed.\n",
    "    for layer in base_model_effnet.layers[:fine_tune_at_effnet]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model_effnet.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "                         loss='categorical_crossentropy',\n",
    "                         metrics=['accuracy'])\n",
    "    # print(\"\\nEfficientNetB0 Model Summary (Full Fine-Tuning):\") # Optional\n",
    "    # model_effnet.summary()\n",
    "    \n",
    "    print(\"\\nFine-tuning EfficientNetB0 (more layers)...\")\n",
    "    initial_epoch_full_ft_effnet = 0\n",
    "    if history_effnet_head and history_effnet_head.epoch:\n",
    "        initial_epoch_full_ft_effnet = history_effnet_head.epoch[-1] + 1\n",
    "        \n",
    "    history_effnet_full = model_effnet.fit(\n",
    "        train_generator_cnn,\n",
    "        epochs=initial_epoch_full_ft_effnet + EPOCHS_FT_FULL,\n",
    "        initial_epoch=initial_epoch_full_ft_effnet,\n",
    "        validation_data=validation_generator_cnn,\n",
    "        callbacks=[early_stopping_effnet]\n",
    "    )\n",
    "    cnn_model_histories['EfficientNetB0_FullFT'] = history_effnet_full\n",
    "    plot_training_history(history_effnet_full, \"EfficientNetB0 (Full Fine-Tuned)\")\n",
    "\n",
    "    if test_generator_cnn:\n",
    "        print(\"\\nEvaluating EfficientNetB0 (Fine-Tuned) on Test Set...\")\n",
    "        effnet_loss, effnet_accuracy = model_effnet.evaluate(test_generator_cnn)\n",
    "        print(f\"EfficientNetB0 Test Accuracy: {effnet_accuracy:.4f}, Test Loss: {effnet_loss:.4f}\")\n",
    "        y_pred_effnet_probs = model_effnet.predict(test_generator_cnn)\n",
    "        y_pred_effnet = np.argmax(y_pred_effnet_probs, axis=1)\n",
    "        evaluate_and_log_model(\"EfficientNetB0_FineTuned\", \"CNN_TransferLearn\", test_generator_cnn.classes, y_pred_effnet, class_names, part3_results_list)\n",
    "    else:\n",
    "        print(\"Test generator not available. Skipping EfficientNetB0 evaluation.\")\n",
    "else:\n",
    "    print(\"Skipping EfficientNetB0 fine-tuning as data generators or class info are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Comments on Part 3 Results\n",
    "*(This section is for your analysis. Fill this in based on actual results. Discuss stopping criteria, loss graphs, and performance of each fine-tuned model.)*\n",
    "\n",
    "* **VGG16 Fine-tuned:**\n",
    "    * Performance: *(Accuracy, Precision, Recall, F1 on test set)*\n",
    "    * Training Process: Describe the loss and accuracy curves. Where did you decide to stop training (or where did EarlyStopping stop it)? Was there overfitting? How did the two-stage fine-tuning (head first, then more layers) impact learning?\n",
    "\n",
    "* **ResNet50 Fine-tuned:**\n",
    "    * Performance: *(Accuracy, Precision, Recall, F1 on test set)*\n",
    "    * Training Process: Similar discussion as for VGG16. How did ResNet50 compare to VGG16 in terms of training stability and final performance?\n",
    "\n",
    "* **EfficientNetB0 Fine-tuned:**\n",
    "    * Performance: *(Accuracy, Precision, Recall, F1 on test set)*\n",
    "    * Training Process: Similar discussion. How did EfficientNetB0 perform? Was it faster to train or did it achieve better results given its design for efficiency?\n",
    "\n",
    "* **Overall Comparison for Part 3:**\n",
    "    * Which pretrained model performed best after fine-tuning? Why do you think that was the case?\n",
    "    * Discuss the importance of freezing the base model initially and then unfreezing layers for further fine-tuning with a lower learning rate.\n",
    "    * How do these results compare to the traditional feature-based methods in Part 1 and 2? (Anticipate a significant improvement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Training Randomly Weighted CNN Models\n",
    "\n",
    "Assign random weights to the CNN models selected for Part 3 and train them from scratch. Compare results with Part 3. Provide similar outcomes (comments, graphs, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part4_results_list = []\n",
    "EPOCHS_SCRATCH = 75 # More epochs might be needed for training from scratch, adjust based on observation\n",
    "\n",
    "def create_cnn_architecture_from_scratch(base_model_class, model_name_str):\n",
    "    \"\"\"Helper to create a CNN model structure with random weights for the base.\"\"\"\n",
    "    base_model = base_model_class(weights=None, include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    base_model.trainable = True # Entire base model is trainable from scratch\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu', kernel_initializer='he_normal'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(NUM_CLASSES, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "    ], name=model_name_str)\n",
    "    return model\n",
    "\n",
    "cnn_architectures_to_train_scratch = {\n",
    "    \"VGG16_Scratch\": VGG16,\n",
    "    \"ResNet50_Scratch\": ResNet50,\n",
    "    \"EfficientNetB0_Scratch\": EfficientNetB0\n",
    "}\n",
    "\n",
    "if train_generator_cnn is not None and validation_generator_cnn is not None and NUM_CLASSES > 0:\n",
    "    for model_name_scratch, base_model_builder in cnn_architectures_to_train_scratch.items():\n",
    "        print(f\"\\n--- Training {model_name_scratch} from Scratch ---\")\n",
    "        \n",
    "        model_scratch = create_cnn_architecture_from_scratch(base_model_builder, model_name_scratch)\n",
    "\n",
    "        model_scratch.compile(optimizer=Adam(learning_rate=0.0005), # Starting LR for scratch models, might need tuning\n",
    "                              loss='categorical_crossentropy',\n",
    "                              metrics=['accuracy'])\n",
    "        model_scratch.summary()\n",
    "\n",
    "        early_stopping_scratch = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "        reduce_lr_scratch = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "        print(f\"Training {model_name_scratch}...\")\n",
    "        history_scratch = model_scratch.fit(\n",
    "            train_generator_cnn,\n",
    "            epochs=EPOCHS_SCRATCH, \n",
    "            validation_data=validation_generator_cnn,\n",
    "            callbacks=[early_stopping_scratch, reduce_lr_scratch]\n",
    "        )\n",
    "        cnn_model_histories[model_name_scratch] = history_scratch\n",
    "        plot_training_history(history_scratch, model_name_scratch)\n",
    "        \n",
    "        if test_generator_cnn:\n",
    "            print(f\"\\nEvaluating {model_name_scratch} on Test Set...\")\n",
    "            loss_scratch, accuracy_scratch = model_scratch.evaluate(test_generator_cnn)\n",
    "            print(f\"{model_name_scratch} Test Accuracy: {accuracy_scratch:.4f}, Test Loss: {loss_scratch:.4f}\")\n",
    "            y_pred_scratch_probs = model_scratch.predict(test_generator_cnn)\n",
    "            y_pred_scratch = np.argmax(y_pred_scratch_probs, axis=1)\n",
    "            evaluate_and_log_model(model_name_scratch, \"CNN_FromScratch\", test_generator_cnn.classes, y_pred_scratch, class_names, part4_results_list)\n",
    "        else:\n",
    "            print(f\"Test generator not available. Skipping {model_name_scratch} evaluation.\")\n",
    "else:\n",
    "    print(\"Skipping Part 4 (CNNs from scratch) as data generators or class info are not available.\")\n",
    "\n",
    "# Display summary of Part 4 results\n",
    "if part4_results_list:\n",
    "    part4_results_df = pd.DataFrame(part4_results_list)\n",
    "    print(\"\\n\\n--- Summary of Part 4 Results (CNNs Trained from Scratch, Test Set) ---\")\n",
    "    print(part4_results_df.to_string())\n",
    "else:\n",
    "    print(\"No models were trained in Part 4, or no results were collected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Comments on Part 4 Results\n",
    "*(This section is for your analysis. Fill this in based on actual results. Compare with Part 3. Provide graphs and comments as in Part 3.)*\n",
    "\n",
    "* **VGG16 (from Scratch):**\n",
    "    * Performance: *(Accuracy, Precision, Recall, F1)*\n",
    "    * Training Process: Discuss loss/accuracy curves. How did training from scratch compare to fine-tuning VGG16? Was it harder to train? Did it achieve comparable performance?\n",
    "\n",
    "* **ResNet50 (from Scratch):**\n",
    "    * Performance: *(Accuracy, Precision, Recall, F1)*\n",
    "    * Training Process: Discuss. Training deeper networks like ResNet50 from scratch can be challenging. How did it fare?\n",
    "\n",
    "* **EfficientNetB0 (from Scratch):**\n",
    "    * Performance: *(Accuracy, Precision, Recall, F1)*\n",
    "    * Training Process: Discuss. EfficientNets are also complex. How did training from scratch go?\n",
    "\n",
    "* **Overall Comparison for Part 4 vs. Part 3:**\n",
    "    * Compare the performance of models trained from scratch (Part 4) versus their fine-tuned counterparts (Part 3). What does this tell you about the value of transfer learning for this dataset size and task?\n",
    "    * Were there significant differences in training time or stability?\n",
    "    * Discuss any particular challenges faced when training these large architectures from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implementing and Training Your Own CNN Model from Scratch\n",
    "\n",
    "Create your own CNN model from scratch using PyTorch or TensorFlow. Aim to determine the best layers and architecture for the given dataset. Share results of all considerable trials. Provide outcomes (comments, graphs) similar to Parts 3 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part5_results_list = []\n",
    "EPOCHS_CUSTOM_CNN = 60 # Adjust as needed, custom models might train faster or need more/less\n",
    "\n",
    "def build_custom_cnn_model_v1(input_shape, num_classes):\n",
    "    \"\"\"Defines a custom CNN architecture (Trial 1).\"\"\"\n",
    "    model = Sequential(name=\"CustomCNN_Trial1\")\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_initializer='he_normal'))\n",
    "    # model.add(BatchNormalization()) # Simplified block 3 slightly\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Flatten and Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='he_normal')) # Reduced dense layer size\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_initializer='glorot_uniform'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "if train_generator_cnn is not None and validation_generator_cnn is not None and NUM_CLASSES > 0:\n",
    "    custom_model_v1 = build_custom_cnn_model_v1((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), NUM_CLASSES)\n",
    "    print(\"Custom CNN Model (Trial 1) Summary:\")\n",
    "    custom_model_v1.summary()\n",
    "\n",
    "    early_stopping_custom = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr_custom = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "    print(\"\\nTraining Custom CNN Model (Trial 1)...\")\n",
    "    history_custom_cnn_v1 = custom_model_v1.fit(\n",
    "        train_generator_cnn,\n",
    "        epochs=EPOCHS_CUSTOM_CNN,\n",
    "        validation_data=validation_generator_cnn,\n",
    "        callbacks=[early_stopping_custom, reduce_lr_custom]\n",
    "    )\n",
    "    cnn_model_histories['CustomCNN_Trial1'] = history_custom_cnn_v1\n",
    "    plot_training_history(history_custom_cnn_v1, \"CustomCNN_Trial1\")\n",
    "\n",
    "    if test_generator_cnn:\n",
    "        print(\"\\nEvaluating Custom CNN Model (Trial 1) on Test Set...\")\n",
    "        custom_loss, custom_accuracy = custom_model_v1.evaluate(test_generator_cnn)\n",
    "        print(f\"Custom CNN (Trial 1) Test Accuracy: {custom_accuracy:.4f}, Test Loss: {custom_loss:.4f}\")\n",
    "        y_pred_custom_probs = custom_model_v1.predict(test_generator_cnn)\n",
    "        y_pred_custom = np.argmax(y_pred_custom_probs, axis=1)\n",
    "        evaluate_and_log_model(\"CustomCNN_Trial1\", \"CNN_Custom\", test_generator_cnn.classes, y_pred_custom, class_names, part5_results_list)\n",
    "    else:\n",
    "        print(\"Test generator not available. Skipping Custom CNN (Trial 1) evaluation.\")\n",
    "else:\n",
    "    print(\"Skipping Part 5 (Custom CNN) as data generators or class info are not available.\")\n",
    "\n",
    "# Display summary of Part 5 results\n",
    "if part5_results_list:\n",
    "    part5_results_df = pd.DataFrame(part5_results_list)\n",
    "    print(\"\\n\\n--- Summary of Part 5 Results (Custom CNN, Test Set) ---\")\n",
    "    print(part5_results_df.to_string())\n",
    "else:\n",
    "    print(\"Custom CNN model was not trained in Part 5, or no results were collected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Comments on Part 5 Results\n",
    "*(This section is for your analysis. Fill this in based on actual results. Discuss your architecture choices, training process, and outcomes. Share results of all considerable trials.)*\n",
    "\n",
    "* **Custom CNN Architecture (Trial 1):**\n",
    "    * Describe your chosen architecture: How many layers, types of layers (Conv, Pooling, Dense), activation functions, number of filters, kernel sizes, dropout, batch normalization, etc.? Justify your choices for this first trial (e.g., based on common practices, previous parts, or literature for moderately sized image datasets).\n",
    "    * Performance: *(Accuracy, Precision, Recall, F1)*\n",
    "    * Training Process: Discuss loss/accuracy curves. How did it train? Was it stable? Overfitting? How many epochs did it run for?\n",
    "\n",
    "* **(Optional) Further Trials:**\n",
    "    * If you tried other architectures or significant hyperparameter changes (e.g., more/fewer layers, different filter sizes, different optimizers, learning rates, dropout rates), describe them here as Trial 2, Trial 3, etc.\n",
    "    * For each trial: Briefly describe the change, report its Performance, and discuss what you learned or why you made the changes from the previous trial. The assignment mentions \"share results of all your considerable trials in the way of the achieving the best\".\n",
    "\n",
    "* **Overall Comparison for Part 5:**\n",
    "    * How did your best custom CNN compare to the fine-tuned pretrained models (Part 3) and those large architectures trained from scratch (Part 4)?\n",
    "    * What were the challenges in designing and training an effective CNN from scratch for this 25-class bird classification problem?\n",
    "    * What future improvements or different architectural ideas could you explore for your custom model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras\n",
    "\n",
    "This section covers additional requirements and analyses as per the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 1: Data Visualization\n",
    "This was covered in Section 1.2 with sample images and class distributions. Additional visualizations relevant to specific model analyses (like confusion matrices with `evaluate_and_log_model` and training history plots) are included within each respective part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 2: Experimentation and Commenting\n",
    "Throughout this notebook, placeholders for comments, interpretations, and discussions about experiments have been provided after each major part (e.g., 1.5, 2.3, 3.4, 4.1, 5.1). It is crucial to fill these sections with detailed reasoning and inferences based on your observed results. The assignment emphasizes that \"commenting is as much important as the experimenting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 3: Evaluation Metrics\n",
    "The `evaluate_and_log_model` function consistently computes and logs Accuracy, Precision (weighted), Recall (weighted), and F1-Score (weighted) for all classification models, as required. Confusion matrices are also plotted. These metrics are vital for understanding model performance beyond simple accuracy, especially in multi-class scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 4: Analysis of Misclassified Examples\n",
    "\"Show the examples that your models are unable to classify correctly, discuss why they are mislabeled. Also discuss the examples that one model successfully predicts but the other not, and vice versa, discuss the reason behind it.\"\n",
    "\n",
    "*(This section requires you to manually inspect misclassified images after running your best models from different parts. You'll need to load some test images, get their true labels and predicted labels, and then display/discuss the incorrect ones.)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_misclassified_images(df_test_subset, y_true_indices, y_pred_indices, class_names_list, num_to_display=10, model_name_str=\"Model\"):\n",
    "    \"\"\"Displays misclassified images based on numeric indices for labels.\"\"\"\n",
    "    if df_test_subset is None or df_test_subset.empty:\n",
    "        print(\"Test dataframe is empty, cannot display misclassified images.\")\n",
    "        return\n",
    "    \n",
    "    if len(y_true_indices) != len(y_pred_indices) or len(y_true_indices) != len(df_test_subset):\n",
    "        print(\"Length mismatch between dataframe, true labels, and predicted labels.\")\n",
    "        return\n",
    "        \n",
    "    misclassified_mask = (np.array(y_true_indices) != np.array(y_pred_indices))\n",
    "    misclassified_df = df_test_subset[misclassified_mask]\n",
    "    misclassified_true_labels = np.array(y_true_indices)[misclassified_mask]\n",
    "    misclassified_pred_labels = np.array(y_pred_indices)[misclassified_mask]\n",
    "\n",
    "    if misclassified_df.empty:\n",
    "        print(f\"No misclassified images found for {model_name_str}!\")\n",
    "        return\n",
    "\n",
    "    print(f\"Displaying up to {num_to_display} misclassified images for {model_name_str}:\")\n",
    "    \n",
    "    actual_num_to_display = min(num_to_display, len(misclassified_df))\n",
    "    sample_misclassified_df = misclassified_df.sample(actual_num_to_display, random_state=42) if actual_num_to_display < len(misclassified_df) else misclassified_df\n",
    "    \n",
    "    # Get corresponding true/pred labels for the sampled misclassified items\n",
    "    # This requires matching indices if sample_misclassified_df is used\n",
    "    # A simpler way is to iterate through a sample of the *indices* of misclassified items\n",
    "    misclassified_indices_original = np.where(misclassified_mask)[0]\n",
    "    display_original_indices = np.random.choice(misclassified_indices_original, size=actual_num_to_display, replace=False)\n",
    "\n",
    "    plt.figure(figsize=(15, max(5, (actual_num_to_display // 5 + 1) * 4) ))\n",
    "    for i, original_idx in enumerate(display_original_indices):\n",
    "        img_path = df_test_subset['filepath'].iloc[original_idx]\n",
    "        true_label_idx = y_true_indices[original_idx]\n",
    "        pred_label_idx = y_pred_indices[original_idx]\n",
    "        true_label_str = class_names_list[true_label_idx] if true_label_idx < len(class_names_list) else \"Unknown_True_Idx\"\n",
    "        pred_label_str = class_names_list[pred_label_idx] if pred_label_idx < len(class_names_list) else \"Unknown_Pred_Idx\"\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            plt.subplot((actual_num_to_display + 4) // 5, 5, i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"True: {true_label_str}\\nPred: {pred_label_str}\", fontsize=9)\n",
    "            plt.axis('off')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "    plt.suptitle(f\"Misclassified Samples by {model_name_str}\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# Placeholder for actual usage after model training and prediction:\n",
    "# This requires you to have:\n",
    "# 1. test_df_processed (the DataFrame for the test set)\n",
    "# 2. y_true_test_numeric (the true numeric labels for the test set, e.g., from test_generator_cnn.classes)\n",
    "# 3. y_pred_model_numeric (the predicted numeric labels from your model for the test set)\n",
    "# 4. class_names (list of class name strings)\n",
    "\n",
    "print(\"\\nExample: To display misclassified images for a model, you would run something like:\")\n",
    "print(\"# if 'y_true_test' in locals() and 'y_pred_some_model' in locals() and test_df_processed is not None:\")\n",
    "print(\"#     display_misclassified_images(test_df_processed, y_true_test, y_pred_some_model, class_names, num_to_display=10, model_name_str='MyBestModel')\")\n",
    "print(\"# Ensure y_true_test and y_pred_some_model are numeric (integer) labels corresponding to class_names indices.\")\n",
    "\n",
    "# You will need to adapt this part after running your models and getting predictions.\n",
    "# For instance, after Part 3 (Fine-tuning EfficientNetB0):\n",
    "# if test_generator_cnn and 'y_pred_effnet' in locals(): # y_pred_effnet was numeric from argmax\n",
    "#    true_labels_for_test_gen = test_generator_cnn.classes\n",
    "#    display_misclassified_images(test_df_processed, true_labels_for_test_gen, y_pred_effnet, class_names, num_to_display=10, model_name_str=\"EfficientNetB0_FineTuned_Example\")\n",
    "# else:\n",
    "#    print(\"\\nNot displaying misclassified images example now as test_generator_cnn or y_pred_effnet might not be defined yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of Misclassified Examples:\n",
    "*(After running your models and the `display_misclassified_images` function with appropriate predictions, add your detailed discussion here. Consider:)*\n",
    "* *Which classes are commonly confused? Are there specific pairs or groups of bird species that the models struggle with?*\n",
    "* *What are the visual characteristics of the misclassified images? (e.g., poor lighting, occlusion, unusual angles, juvenile birds, intra-species variation, high similarity to other species).*\n",
    "* *Are there patterns in misclassifications that suggest limitations of the feature extraction methods (for Part 1/2) or the CNN architectures?*\n",
    "* *If comparing two models (e.g., a traditional model vs. a CNN, or two different CNNs):*\n",
    "    * *Show examples where Model A is correct and Model B is wrong.* What might Model A be capturing that Model B misses?\n",
    "    * *Show examples where Model B is correct and Model A is wrong.* What might Model B be capturing that Model A misses?\n",
    "    * *This comparison helps understand the relative strengths and weaknesses of the models more deeply.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra 5: Overall Comparison and Conclusion\n",
    "\"Remember to compare the result of the each step with the all others, and also compare the sub-results of the steps in the step itself.\"\n",
    "\n",
    "*(This is a summary section where you bring together all your findings from `part1_results_df`, `part2_results_df`, `part3_results_list`, `part4_results_list`, `part5_results_list` and your qualitative observations.)*\n",
    "\n",
    "1.  **Summary of Performance Across All Parts:**\n",
    "    * Create a master table or refer to the individual summary tables (e.g., `part1_results_df`, etc.) to compare the best performing model/feature combination from each part (Part 1, Part 2, Part 3, Part 4, Part 5) based on key metrics like Accuracy and F1-score on the test set.\n",
    "\n",
    "2.  **Part 1 (Traditional Features + ML) vs. Part 2 (PCA/Selection + ML):**\n",
    "    * Which traditional feature set (Color Histogram, HOG, SIFT Aggregated) performed best in Part 1 before dimensionality reduction/selection?\n",
    "    * How did applying PCA affect the performance of models for each feature type? Did it improve accuracy, F1-score, or training time? By how much?\n",
    "    * How did applying SelectKBest affect performance? Was it more or less effective than PCA for the different feature types?\n",
    "    * Overall, did dimensionality reduction or feature selection offer a clear advantage for traditional methods in this task?\n",
    "\n",
    "3.  **Traditional ML (Best of Parts 1 & 2) vs. CNNs (Parts 3, 4, 5):**\n",
    "    * Compare the best model from Parts 1/2 with the fine-tuned CNNs (Part 3), CNNs trained from scratch with known architectures (Part 4), and your custom CNN (Part 5).\n",
    "    * Quantify the difference in performance (e.g., % increase in accuracy/F1-score).\n",
    "    * Discuss the trade-offs in terms of implementation complexity, computational resources required, and training time.\n",
    "\n",
    "4.  **Fine-tuned CNNs (Part 3) vs. CNNs from Scratch (Part 4 & Part 5):**\n",
    "    * How did the fine-tuned models (VGG16, ResNet50, EfficientNetB0) compare against their counterparts trained from scratch using the same architectures?\n",
    "    * How did your best custom CNN (Part 5) perform relative to the pretrained architectures (both fine-tuned and from scratch)?\n",
    "    * What does this indicate about the effectiveness of transfer learning versus training from scratch for this specific dataset size and complexity?\n",
    "\n",
    "5.  **Strengths and Weaknesses of Algorithms Observed:**\n",
    "    * Reflect on the general strengths and weaknesses you observed for different categories of algorithms:\n",
    "        * Traditional feature engineering + classical ML classifiers.\n",
    "        * Transfer learning with deep CNNs.\n",
    "        * Training deep CNNs (standard architectures) from scratch.\n",
    "        * Training a custom CNN architecture from scratch.\n",
    "    * Consider aspects like data requirements, sensitivity to hyperparameters, tendency to overfit, interpretability (if applicable), and computational cost.\n",
    "\n",
    "6.  **Final Conclusion and Learnings:**\n",
    "    * Based on all your experiments, which approach and specific model would you recommend for this bird species classification task and why?\n",
    "    * What are the most significant learnings you gained from completing this comprehensive machine learning project?\n",
    "    * If you had more time or resources, what are 1-2 key experiments or improvements you would prioritize to potentially achieve even better performance or understanding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Requirements & Environment\n",
    "\n",
    "This Jupyter Notebook (`assignment4.ipynb`) contains all code and the integrated report. The code is commented to explain the steps. After running all cells, the outputs (tables, graphs) will be embedded in the notebook.\n",
    "\n",
    "### Necessary Libraries and Versions\n",
    "\"Note that your report also has to contain necessary libraries to be installed with the versions that are used (!pip install commands are preferred).\"\n",
    "\n",
    "To run this notebook, the following libraries are recommended. You should update these with the exact versions from your environment after running `pip freeze`.\n",
    "\n",
    "**Instructions for listing versions:**\n",
    "1. Activate your Python virtual environment where you ran this notebook.\n",
    "2. Run the command: `pip freeze`\n",
    "3. Copy the relevant lines for the libraries listed below and paste them into the code block.\n",
    "\n",
    "```python\n",
    "# !pip install numpy==<version_you_used>\n",
    "# !pip install pandas==<version_you_used>\n",
    "# !pip install matplotlib==<version_you_used>\n",
    "# !pip install seaborn==<version_you_used>\n",
    "# !pip install scikit-learn==<version_you_used>\n",
    "# !pip install Pillow==<version_you_used>\n",
    "# !pip install opencv-python==<version_you_used>\n",
    "# !pip install opencv-contrib-python==<version_you_used>  # For SIFT\n",
    "# !pip install scikit-image==<version_you_used>         # For HOG\n",
    "# !pip install tensorflow==<version_you_used>             # Or your specific TF variant e.g., tensorflow-gpu\n",
    "```\n",
    "\n",
    "*(Please replace `<version_you_used>` with the actual versions from your working environment where you successfully ran this notebook. Uncomment the lines above and fill them in your final submission.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Hierarchy\n",
    "As per the assignment instructions:\n",
    "```\n",
    "<GroupID>.zip\n",
    "└── assignment4.ipynb\n",
    "```\n",
    "If you include any external images in your report (not generated by code), they should also be in the zip file as per the optional part of the hierarchy: `*.(jpg|jpeg|png|gif|tif|tiff|bmp|svg|webp) (optional)`.\n",
    "\n",
    "Do not send the dataset itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}